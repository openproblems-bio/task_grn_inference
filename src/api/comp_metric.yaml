functionality:
  namespace: "metrics"
  info:
    type: metrics
    type_info:
      label: Label
      summary: A metric to evaluate the performance of the inferred GRN
      description: |
        A metric to evaluate the performance of the inferred GRN
  arguments: 
    - name: --perturbation_data
      __merge__: file_perturbation_h5ad.yaml
      required: false
      direction: input
    - name: --prediction
      __merge__: file_prediction.yaml
      required: true
      direction: input
    - name: --score
      __merge__: file_score.yaml
      required: false
      direction: output
    - name: --tf_all
      type: file
      direction: input
      required: true
      example: resources_test/prior/tf_all.csv
    - name: --reg_type
      type: string
      direction: input
      default: ridge
      description: name of regretion to use
      multiple: false
    - name: --subsample
      type: integer
      direction: input
      default: -1
      description: number of samples randomly drawn from perturbation data
    - name: --num_workers
      type: integer
      direction: input
      default: 4
    - name: --method_id 
      type: string 
      direction: input 
      required: false
      example: collectri
    - name: --apply_tf
      type: boolean 
      required: false
      default: true
    - name: --clip_scores
      type: boolean 
      required: false
      default: true
      description: clips the r2 scores for each gene to make them within [0, 1]
    - name: --layer
      type: string
      direction: input
      required: false
      default: scgen_pearson
    - name: --max_n_links
      type: integer
      default: 50000
    - name: --verbose
      type: integer
      default: 2
      direction: input
    - name: --skeleton 
      type: file
      direction: input
      example: resources/prior/skeleton.csv'
    - name: --apply_skeleton 
      type: boolean
      direction: input
      default: true



      
  test_resources:
    - type: python_script
      path: /src/common/component_tests/run_and_check_output.py
    - path: /resources_test/grn-benchmark
      dest: resources_test/grn-benchmark
    - path: /resources_test/prior
      dest: resources_test/prior
    - path: /resources_test/grn_models
      dest: resources_test/grn_models
