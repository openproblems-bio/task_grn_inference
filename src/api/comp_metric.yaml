functionality:
  namespace: "metrics"
  info:
    type: metrics
    type_info:
      label: Label
      summary: A metric to evaluate the performance of the inferred GRN
      description: |
        A metric to evaluate the performance of the inferred GRN
  arguments: 
    - name: --evaluation_data
      __merge__: file_evaluation_h5ad.yaml
      required: false
      direction: input
    - name: --prediction
      __merge__: file_prediction.yaml
      required: true
      direction: input
    - name: --score
      __merge__: file_score.yaml
      required: false
      direction: output
    - name: --tf_all
      type: file
      direction: input
      required: true
      example: resources_test/prior/tf_all.csv
    - name: --reg_type
      type: string
      direction: input
      default: ridge
      description: name of regretion to use
      multiple: false
    - name: --subsample
      type: integer
      direction: input
      default: -1
      description: number of samples randomly drawn from perturbation data
    - name: --num_workers
      type: integer
      direction: input
      default: 4
    - name: --method_id 
      type: string 
      direction: input 
      required: false
      example: collectri
    - name: --apply_tf
      type: boolean 
      required: false
      default: true

    - name: --layer
      type: string
      direction: input
      required: false
      default: X_norm
    - name: --max_n_links
      type: integer
      default: 50000
    - name: --verbose
      type: integer
      default: 2
      direction: input
    - name: --skeleton 
      type: file
      direction: input
      example: resources_test/prior/skeleton.csv
    - name: --apply_skeleton 
      type: boolean
      direction: input
      default: false

  test_resources:
    - type: python_script
      path: /src/common/component_tests/run_and_check_output.py
    - path: /resources_test/
      dest: resources_test/
