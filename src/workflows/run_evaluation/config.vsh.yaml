

name: run_grn_evaluation
namespace: "workflows"
info:
  label: run_grn_evaluation
  summary: "Evaluates GRNs and provides scores using regression analysis."

argument_groups:
  - name: Inputs
    arguments:
      - name: --evaluation_data
        type: file
        required: true
        direction: input
      - name: --evaluation_data_de
        type: file
        required: false
        direction: input
      - name: --evaluation_data_sc
        type: file
        required: false
        direction: input
        example: 'resources_test/datasets_raw/adamson_sc_counts.h5ad'
      - name: --prediction
        type: file
        required: true
        direction: input
      - name: --tf_all
        type: file
        direction: input
        required: true
        example: resources_test/grn_benchmark/prior/tf_all.csv
      - name: --reg_type
        type: string
        direction: input
        default: ridge
        description: name of regretion to use
        multiple: false
      - name: --subsample
        type: integer
        direction: input
        default: -1
        description: number of samples randomly drawn from perturbation data
      - name: --num_workers
        type: integer
        direction: input
        default: 4
      - name: --apply_tf
        type: boolean 
        required: false
        default: true
      - name: --layer
        type: string
        direction: input
      - name: --regulators_consensus
        type: file
        direction: input
        must_exist: false
        required: true
        example: resources_test/grn_benchmark/prior/regulators_consensus_norman.json
      - name: --ws_consensus
        type: file
        direction: input
        must_exist: false
        required: false
        example: resources_test/grn_benchmark/prior/ws_consensus_norman.csv 
      - name: --ws_distance_background
        type: file
        direction: input
        must_exist: false
        required: false
        example: resources_test/grn_benchmark/prior/ws_distance_background_norman.csv
      # - name: --ground_truth_unibind
      #   type: file
      #   direction: input
      #   must_exist: false
      #   required: false
      # - name: --ground_truth_chipatlas
      #   type: file
      #   direction: input
      #   must_exist: false
      #   required: false
      # - name: --ground_truth_remap
      #   type: file
      #   direction: input
      #   must_exist: false
      #   required: false
      
      
  - name: Outputs
    arguments:
      - name: "--scores"
        type: file
        required: true
        direction: output
        default: score_uns.yaml
      - name: "--metric_configs"
        type: file
        required: true
        direction: output
        default: metric_configs.yaml

  - name: Arguments
    arguments: 
      - name: "--metric_ids"
        type: string
        multiple: true
        description: A list of metric ids to run. If not specified, all metric will be run.
  

resources:
  - type: nextflow_script
    path: main.nf
    entrypoint: run_wf


dependencies:
  - name: metrics/regression 
  - name: metrics/ws_distance
  - name: metrics/tf_recovery
  - name: metrics/vc
  - name: metrics/rc_tf_act
  - name: metrics/sem
  - name: metrics/ar
  - name: metrics/tf_binding
  - name: metrics/gs_recovery
  - name: utils/extract_uns_metadata
    repository: openproblems

runners:
  - type: executable
  - type: nextflow