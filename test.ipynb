{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from grn_benchmark.src.helper import plot_heatmap, DATASETS, METHODS\n",
    "from task_grn_inference.src.utils.config import METRICS\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'vc'\n",
    "\n",
    "df = pd.read_csv(f'output/{metric}/summary.csv')\n",
    "for dataset in df['dataset'].unique():\n",
    "    df_subset = df[df['dataset'] == dataset]\n",
    "    try:\n",
    "        df_subset = df_subset.pivot(index='method', columns='metric', values='value')\n",
    "    except:\n",
    "        df_subset = df_subset.set_index('method').drop(columns=['dataset'])\n",
    "    # df_subset = df_subset[[c for c in METRICS if c in df_subset.columns]]\n",
    "    for col in df_subset.columns:\n",
    "        if 'f1' in col:\n",
    "            df_subset.sort_values(col, ascending=False, inplace=True)\n",
    "            break\n",
    "    else:\n",
    "        df_subset.sort_values(df_subset.columns[0], ascending=False, inplace=True)\n",
    "    fig, ax = plt.subplots(figsize=(1*len(df_subset.columns), .5*len(df_subset)))\n",
    "    plot_heatmap(df_subset, name='',  cmap=\"viridis\", ax=ax)\n",
    "    plt.title(f'{dataset}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble the results from differnet runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r resources/results/all_main/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied identical file: method_configs.yaml\n",
      "Copied identical file: metric_configs.yaml\n",
      "Merged: dataset_uns.yaml\n",
      "Merged: score_uns.yaml\n",
      "Merged: trace.txt (duplicates removed)\n",
      "Copied unique file: state.yaml → state.yaml\n",
      "Copied unique file: op_.celloracle.celloracle.prediction.h5ad → op_.celloracle.celloracle.prediction.h5ad\n",
      "Copied unique file: scplus_mdata.h5mu.2DAaAA8E → scplus_mdata.h5mu.2DAaAA8E\n",
      "Copied unique file: op_.negative_control.negative_control.prediction.h5ad → op_.negative_control.negative_control.prediction.h5ad\n",
      "Copied unique file: op_.scenicplus.scenicplus.prediction.h5ad → op_.scenicplus.scenicplus.prediction.h5ad\n",
      "Copied unique file: op_.portia.portia.prediction.h5ad → op_.portia.portia.prediction.h5ad\n",
      "Copied unique file: op_.granie.granie.prediction.h5ad → op_.granie.granie.prediction.h5ad\n",
      "Copied unique file: op_.scprint.scprint.prediction.h5ad → op_.scprint.scprint.prediction.h5ad\n",
      "Copied unique file: op_.pearson_corr.pearson_corr.prediction.h5ad → op_.pearson_corr.pearson_corr.prediction.h5ad\n",
      "Copied unique directory: output → output\n",
      "Copied unique file: op_.scglue.scglue.prediction.h5ad → op_.scglue.scglue.prediction.h5ad\n",
      "Copied unique file: op_.ppcor.ppcor.prediction.h5ad → op_.ppcor.ppcor.prediction.h5ad\n",
      "Copied unique file: op_.positive_control.positive_control.prediction.h5ad → op_.positive_control.positive_control.prediction.h5ad\n",
      "Copied unique file: op_.scenic.scenic.prediction.h5ad → op_.scenic.scenic.prediction.h5ad\n",
      "Copied unique file: op_.figr.figr.prediction.h5ad → op_.figr.figr.prediction.h5ad\n",
      "Copied unique file: task_info.yaml → task_info.yaml\n",
      "Copied unique file: op_.grnboost2.grnboost2.prediction.h5ad → op_.grnboost2.grnboost2.prediction.h5ad\n",
      "Copied unique file: state.yaml → state_nakatake.yaml\n",
      "Copied unique file: nakatake_.positive_control.positive_control.prediction.h5ad → nakatake_.positive_control.positive_control.prediction.h5ad\n",
      "Copied unique file: nakatake_.portia.portia.prediction.h5ad → nakatake_.portia.portia.prediction.h5ad\n",
      "Copied unique file: nakatake_.grnboost.grnboost.prediction.h5ad → nakatake_.grnboost.grnboost.prediction.h5ad\n",
      "Copied unique file: nakatake_.ppcor.ppcor.prediction.h5ad → nakatake_.ppcor.ppcor.prediction.h5ad\n",
      "Copied unique file: nakatake_.pearson_corr.pearson_corr.prediction.h5ad → nakatake_.pearson_corr.pearson_corr.prediction.h5ad\n",
      "Copied unique file: nakatake_.negative_control.negative_control.prediction.h5ad → nakatake_.negative_control.negative_control.prediction.h5ad\n",
      "Copied unique file: nakatake_.scenic.scenic.prediction.h5ad → nakatake_.scenic.scenic.prediction.h5ad\n",
      "Copied unique file: task_info.yaml → task_info_nakatake.yaml\n",
      "Copied unique file: norman_.grnboost2.grnboost2.prediction.h5ad → norman_.grnboost2.grnboost2.prediction.h5ad\n",
      "Copied unique file: state.yaml → state_norman.yaml\n",
      "Copied unique file: norman_.ppcor.ppcor.prediction.h5ad → norman_.ppcor.ppcor.prediction.h5ad\n",
      "Copied unique file: norman_.scprint.scprint.prediction.h5ad → norman_.scprint.scprint.prediction.h5ad\n",
      "Copied unique file: norman_.pearson_corr.pearson_corr.prediction.h5ad → norman_.pearson_corr.pearson_corr.prediction.h5ad\n",
      "Copied unique file: norman_.portia.portia.prediction.h5ad → norman_.portia.portia.prediction.h5ad\n",
      "Copied unique file: norman_.negative_control.negative_control.prediction.h5ad → norman_.negative_control.negative_control.prediction.h5ad\n",
      "Copied unique file: norman_.scenic.scenic.prediction.h5ad → norman_.scenic.scenic.prediction.h5ad\n",
      "Copied unique file: norman_.positive_control.positive_control.prediction.h5ad → norman_.positive_control.positive_control.prediction.h5ad\n",
      "Copied unique file: task_info.yaml → task_info_norman.yaml\n",
      "Copied unique file: state.yaml → state_replogle.yaml\n",
      "Copied unique file: replogle_.pearson_corr.pearson_corr.prediction.h5ad → replogle_.pearson_corr.pearson_corr.prediction.h5ad\n",
      "Copied unique file: replogle_.positive_control.positive_control.prediction.h5ad → replogle_.positive_control.positive_control.prediction.h5ad\n",
      "Copied unique file: replogle_.portia.portia.prediction.h5ad → replogle_.portia.portia.prediction.h5ad\n",
      "Copied unique file: replogle_.grnboost2.grnboost2.prediction.h5ad → replogle_.grnboost2.grnboost2.prediction.h5ad\n",
      "Copied unique file: replogle_.negative_control.negative_control.prediction.h5ad → replogle_.negative_control.negative_control.prediction.h5ad\n",
      "Copied unique file: replogle_.ppcor.ppcor.prediction.h5ad → replogle_.ppcor.ppcor.prediction.h5ad\n",
      "Copied unique file: task_info.yaml → task_info_replogle.yaml\n",
      "Copied unique file: replogle_.scenic.scenic.prediction.h5ad → replogle_.scenic.scenic.prediction.h5ad\n",
      "Copied unique file: state.yaml → state_adamson.yaml\n",
      "Copied unique file: adamson_.portia.portia.prediction.h5ad → adamson_.portia.portia.prediction.h5ad\n",
      "Copied unique file: adamson_.negative_control.negative_control.prediction.h5ad → adamson_.negative_control.negative_control.prediction.h5ad\n",
      "Copied unique file: adamson_.pearson_corr.pearson_corr.prediction.h5ad → adamson_.pearson_corr.pearson_corr.prediction.h5ad\n",
      "Copied unique file: adamson_.ppcor.ppcor.prediction.h5ad → adamson_.ppcor.ppcor.prediction.h5ad\n",
      "Copied unique file: adamson_.scenic.scenic.prediction.h5ad → adamson_.scenic.scenic.prediction.h5ad\n",
      "Copied unique file: adamson_.grnboost2.grnboost2.prediction.h5ad → adamson_.grnboost2.grnboost2.prediction.h5ad\n",
      "Copied unique file: adamson_.positive_control.positive_control.prediction.h5ad → adamson_.positive_control.positive_control.prediction.h5ad\n",
      "Copied unique file: task_info.yaml → task_info_adamson.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "\n",
    "base_dir = 'resources/results/'\n",
    "save_dir = 'resources/results/all_main/'\n",
    "runs = ['op', 'nakatake', 'norman', 'replogle', 'adamson']\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 1. Copy one version of the identical files\n",
    "identical_files = ['method_configs.yaml', 'metric_configs.yaml']\n",
    "for fname in identical_files:\n",
    "    src = os.path.join(base_dir, f'{runs[0]}_run', fname)\n",
    "    dst = os.path.join(save_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    print(f\"Copied identical file: {fname}\")\n",
    "\n",
    "# 2. Merge dataset_uns.yaml by appending all contents\n",
    "merged_uns = []\n",
    "for run in runs:\n",
    "    path = os.path.join(base_dir, f'{run}_run', 'dataset_uns.yaml')\n",
    "\n",
    "    with open(path, 'r') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "        merged_uns.extend(data)\n",
    "        \n",
    "with open(os.path.join(save_dir, 'dataset_uns.yaml'), 'w') as f:\n",
    "    yaml.dump(merged_uns, f)\n",
    "print(\"Merged: dataset_uns.yaml\")\n",
    "\n",
    "# 3. Merge score_uns.yaml similarly\n",
    "merged_scores = []\n",
    "for run in runs:\n",
    "    path = os.path.join(base_dir, f'{run}_run', 'score_uns.yaml')\n",
    "\n",
    "    with open(path, 'r') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "        # - remove those with missing (because of the metric)\n",
    "        data = [d for d in data if d is not None and 'missing' not in str(d)]\n",
    "        \n",
    "        # print(str(data[0]))\n",
    "        # aa\n",
    "        # missing\n",
    "        if data:\n",
    "            if isinstance(data, dict):\n",
    "                merged_scores.append(data)\n",
    "            elif isinstance(data, list):\n",
    "                merged_scores.extend(data)\n",
    "            else:\n",
    "                print(f\"Unexpected format in {path}: {type(data)}\")\n",
    "\n",
    "with open(os.path.join(save_dir, 'score_uns.yaml'), 'w') as f:\n",
    "    yaml.dump(merged_scores, f)\n",
    "print(\"Merged: score_uns.yaml\")\n",
    "\n",
    "# 4. Merge trace.txt with deduplication\n",
    "seen_lines = OrderedDict()\n",
    "for run in runs:\n",
    "    path = os.path.join(base_dir, f'{run}_run', 'trace.txt')\n",
    "    \n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            seen_lines[line] = None\n",
    "\n",
    "with open(os.path.join(save_dir, 'trace.txt'), 'w') as f:\n",
    "    for line in seen_lines.keys():\n",
    "        f.write(line)\n",
    "df = pd.read_csv(os.path.join(save_dir, 'trace.txt'), sep='\\t')\n",
    "df = df.drop_duplicates(subset=['name'])\n",
    "df.to_csv(os.path.join(save_dir, 'trace.txt'), sep='\\t')\n",
    "print(\"Merged: trace.txt (duplicates removed)\")\n",
    "\n",
    "# 5. Copy other unknown files/directories\n",
    "all_known = set(identical_files + ['dataset_uns.yaml', 'score_uns.yaml', 'trace.txt'])\n",
    "\n",
    "for run in runs:\n",
    "    run_dir = Path(base_dir) / f'{run}_run'\n",
    "    for file_path in run_dir.iterdir():\n",
    "        if file_path.name in all_known:\n",
    "            continue\n",
    "\n",
    "        dest_path = Path(save_dir) / file_path.name\n",
    "\n",
    "        if dest_path.exists():\n",
    "            dest_path = Path(save_dir) / f\"{file_path.stem}_{run}{file_path.suffix}\"\n",
    "\n",
    "        if file_path.is_file():\n",
    "            shutil.copyfile(file_path, dest_path)\n",
    "            print(f\"Copied unique file: {file_path.name} → {dest_path.name}\")\n",
    "        elif file_path.is_dir():\n",
    "            shutil.copytree(file_path, dest_path)\n",
    "            print(f\"Copied unique directory: {file_path.name} → {dest_path.name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
